# Scripts YOLOv12-Face

Ce dossier contient les scripts pour prÃ©parer le dataset WIDERFace et entraÃ®ner YOLOv12 pour la dÃ©tection de visages.

## ğŸ“‹ Scripts disponibles

### 1. `prepare_widerface.py`
Script Python principal pour tÃ©lÃ©charger et prÃ©parer le dataset WIDERFace.

**Utilisation :**
```bash
python scripts/prepare_widerface.py --output datasets/widerface
```

**Options :**
- `--output` : RÃ©pertoire de sortie (dÃ©faut: `datasets/widerface`)
- `--gdrive` : Utiliser Google Drive pour le tÃ©lÃ©chargement

**FonctionnalitÃ©s :**
- âœ… TÃ©lÃ©chargement automatique depuis HuggingFace ou Google Drive
- âœ… Extraction des archives ZIP
- âœ… Conversion des annotations au format YOLO
- âœ… CrÃ©ation du fichier `data.yaml` pour Ultralytics
- âœ… VÃ©rification de l'intÃ©gritÃ© du dataset

### 2. `get_widerface.sh` (Linux/Mac)
Script bash pour tÃ©lÃ©charger le dataset sur Linux/Mac.

```bash
chmod +x scripts/get_widerface.sh
./scripts/get_widerface.sh [output_dir] [use_gdrive]
```

### 3. `get_widerface.bat` (Windows)
Script batch pour tÃ©lÃ©charger le dataset sur Windows.

```cmd
scripts\get_widerface.bat [output_dir]
```

### 4. `train_yolov12_face.py`
Script d'entraÃ®nement utilisant l'API Ultralytics.

**Utilisation basique :**
```bash
# EntraÃ®ner YOLOv12n
python scripts/train_yolov12_face.py --model yolov12n.yaml --epochs 100

# EntraÃ®ner YOLOv12s avec batch size personnalisÃ©
python scripts/train_yolov12_face.py --model yolov12s.yaml --batch-size 32

# Reprendre l'entraÃ®nement
python scripts/train_yolov12_face.py --resume --name mon_experience
```

**Options principales :**
- `--model` : Configuration du modÃ¨le (yolov12n/s/m/l/x.yaml)
- `--data` : Fichier de donnÃ©es (dÃ©faut: datasets/widerface/data.yaml)
- `--epochs` : Nombre d'epochs (dÃ©faut: 300)
- `--batch-size` : Taille du batch (dÃ©faut: 16)
- `--img-size` : Taille des images (dÃ©faut: 640)
- `--device` : Device cuda/cpu (dÃ©faut: auto)
- `--resume` : Reprendre l'entraÃ®nement

**Modes :**
```bash
# EntraÃ®nement
python scripts/train_yolov12_face.py --mode train

# Validation
python scripts/train_yolov12_face.py --mode val --weights runs/train/exp/weights/best.pt

# Export
python scripts/train_yolov12_face.py --mode export --weights runs/train/exp/weights/best.pt --formats onnx torchscript
```

## ğŸš€ Workflow complet

### 1. PrÃ©parer le dataset
```bash
# TÃ©lÃ©charger et prÃ©parer WIDERFace
python scripts/prepare_widerface.py
```

### 2. EntraÃ®ner le modÃ¨le
```bash
# EntraÃ®ner YOLOv12n pour 100 epochs
python scripts/train_yolov12_face.py --model yolov12n.yaml --epochs 100
```

### 3. Valider le modÃ¨le
```bash
# Valider sur le dataset de validation
python scripts/train_yolov12_face.py --mode val --weights runs/train/exp/weights/best.pt
```

### 4. Exporter le modÃ¨le
```bash
# Exporter en ONNX et TorchScript
python scripts/train_yolov12_face.py --mode export --weights runs/train/exp/weights/best.pt
```

## ğŸ“Š Structure du dataset

AprÃ¨s prÃ©paration, le dataset aura cette structure :
```
datasets/widerface/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/      # Images d'entraÃ®nement
â”‚   â”œâ”€â”€ val/        # Images de validation
â”‚   â””â”€â”€ test/       # Images de test
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ train/      # Labels YOLO (format txt)
â”‚   â”œâ”€â”€ val/        # Labels YOLO
â”‚   â””â”€â”€ test/       # Labels YOLO
â””â”€â”€ data.yaml       # Configuration du dataset
```

## ğŸ”§ DÃ©pannage

### Erreur de tÃ©lÃ©chargement
- Essayez l'option `--gdrive` pour utiliser Google Drive
- VÃ©rifiez votre connexion Internet
- Installez `gdown` : `pip install gdown`

### Erreur de mÃ©moire GPU
- RÃ©duisez le batch size : `--batch-size 8`
- RÃ©duisez la taille des images : `--img-size 320`
- Utilisez le CPU : `--device cpu`

### Dataset non trouvÃ©
- VÃ©rifiez que le dataset est dans `datasets/widerface/`
- VÃ©rifiez le chemin dans `data.yaml`
- Relancez `prepare_widerface.py`

## ğŸ“ Notes

- Le dataset WIDERFace contient environ 32k images
- L'entraÃ®nement complet peut prendre plusieurs heures/jours selon le GPU
- Les meilleurs rÃ©sultats sont obtenus avec 300+ epochs
- Utilisez TensorBoard pour suivre l'entraÃ®nement : `tensorboard --logdir runs/train`
